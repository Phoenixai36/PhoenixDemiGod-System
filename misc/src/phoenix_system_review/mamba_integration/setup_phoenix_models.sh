#!/bin/bash

# Phoenix DemiGod Model Setup Script
# Descarga y configura modelos Mamba/SSM para procesamiento 100% local

set -e

echo "ðŸš€ Phoenix DemiGod - Setup de Modelos Mamba/SSM"
echo "================================================"

# Colores para output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Verificar que Ollama estÃ¡ instalado
if ! command -v ollama &> /dev/null; then
    echo -e "${RED}âŒ Ollama no estÃ¡ instalado${NC}"
    echo "Instala Ollama desde: https://ollama.ai"
    exit 1
fi

echo -e "${GREEN}âœ… Ollama encontrado${NC}"

# Verificar que Ollama estÃ¡ corriendo
if ! curl -s http://localhost:11434/api/tags > /dev/null; then
    echo -e "${YELLOW}âš ï¸  Iniciando Ollama...${NC}"
    ollama serve &
    sleep 5
fi

echo -e "${GREEN}âœ… Ollama estÃ¡ corriendo${NC}"

# FunciÃ³n para descargar modelo con verificaciÃ³n
download_model() {
    local model_name=$1
    local description=$2
    
    echo -e "${BLUE}ðŸ“¥ Descargando $description ($model_name)...${NC}"
    
    if ollama list | grep -q "$model_name"; then
        echo -e "${YELLOW}âš ï¸  $model_name ya estÃ¡ descargado${NC}"
    else
        if ollama pull "$model_name"; then
            echo -e "${GREEN}âœ… $model_name descargado correctamente${NC}"
        else
            echo -e "${RED}âŒ Error descargando $model_name${NC}"
            return 1
        fi
    fi
}

# Descargar modelos segÃºn especificaciÃ³n
echo -e "${BLUE}ðŸ§  Descargando modelos Mamba/SSM y fallbacks...${NC}"

# Modelo principal para cÃ³digo (Mamba-based)
download_model "deepseek-coder:6.7b" "Modelo principal para anÃ¡lisis de cÃ³digo"

# Modelo Mamba para razonamiento (si estÃ¡ disponible)
# Nota: Algunos modelos Mamba pueden no estar en Ollama aÃºn
download_model "llama3.2:8b" "Modelo de razonamiento (fallback transformer)"

# Modelo de fallback general
download_model "llama3.2:3b" "Modelo de fallback ligero"

# Modelo especialista en cÃ³digo
download_model "qwen2.5-coder:7b" "Especialista en cÃ³digo avanzado"

# Verificar modelos descargados
echo -e "${BLUE}ðŸ“‹ Modelos disponibles:${NC}"
ollama list

# Crear archivo de configuraciÃ³n .env
echo -e "${BLUE}âš™ï¸  Creando configuraciÃ³n...${NC}"

cat > .env << EOF
# Phoenix DemiGod Model Configuration
# ConfiguraciÃ³n de modelos para router multi-modelo

# Modelo principal (mÃ¡s eficiente)
DEFAULTMODEL=deepseek-coder:6.7b

# Modelo para razonamiento (Mamba cuando estÃ© disponible)
AGENTICMODEL=llama3.2:8b

# Modelo de fallback
FALLBACKMODEL=llama3.2:3b

# Especialista en cÃ³digo
SPECIALISTMODEL=qwen2.5-coder:7b

# ConfiguraciÃ³n de inferencia
QUANTIZATION=4bit
INFERENCEMODE=LOCAL
AGENTMODE=true
ENABLEFALLBACK=true

# Ollama configuration
OLLAMA_BASE_URL=http://localhost:11434

# Monitoring
PROMETHEUS_ENABLED=true
GRAFANA_ENABLED=true

# Energy efficiency targets
ENERGY_REDUCTION_TARGET=65
MAX_WATTS_PER_INFERENCE=150
EOF

echo -e "${GREEN}âœ… Archivo .env creado${NC}"

# Crear script de test
echo -e "${BLUE}ðŸ§ª Creando script de test...${NC}"

cat > test_phoenix_router.py << 'EOF'
#!/usr/bin/env python3
"""
Test script para Phoenix DemiGod Model Router
Verifica que todos los modelos funcionan correctamente
"""

import asyncio
import httpx
import json
import time

async def test_phoenix_router():
    """Test del router multi-modelo"""
    
    base_url = "http://localhost:8000"
    
    # Test queries
    test_queries = [
        {
            "task": "Explica la eficiencia de Mamba vs Transformers",
            "task_type": "reasoning",
            "description": "Test de razonamiento"
        },
        {
            "task": "Analiza este cÃ³digo Python: def fibonacci(n): return n if n <= 1 else fibonacci(n-1) + fibonacci(n-2)",
            "task_type": "code_analysis", 
            "description": "Test de anÃ¡lisis de cÃ³digo"
        },
        {
            "task": "Â¿CuÃ¡les son las mejores prÃ¡cticas para contenedores Docker?",
            "task_type": "general_query",
            "description": "Test de consulta general"
        }
    ]
    
    print("ðŸ§ª Testing Phoenix DemiGod Model Router")
    print("=" * 50)
    
    async with httpx.AsyncClient(timeout=60.0) as client:
        
        # Test health check
        try:
            response = await client.get(f"{base_url}/health")
            if response.status_code == 200:
                health = response.json()
                print(f"âœ… Health Check: {health['status']}")
                print(f"ðŸ“Š Ollama Connection: {health['ollama_connection']}")
                print(f"ðŸ¤– Available Models: {len(health['available_models'])}")
            else:
                print(f"âŒ Health check failed: {response.status_code}")
                return
        except Exception as e:
            print(f"âŒ Cannot connect to Phoenix Router: {e}")
            print("ðŸ’¡ Make sure to run: python phoenix_model_router.py")
            return
        
        # Test queries
        for i, query in enumerate(test_queries, 1):
            print(f"\nðŸ” Test {i}: {query['description']}")
            print(f"ðŸ“ Query: {query['task'][:50]}...")
            
            start_time = time.time()
            
            try:
                response = await client.post(
                    f"{base_url}/phoenixquery",
                    json=query
                )
                
                if response.status_code == 200:
                    result = response.json()
                    duration = time.time() - start_time
                    
                    print(f"âœ… Success!")
                    print(f"ðŸ¤– Model Used: {result['model_used']}")
                    print(f"âš¡ Inference Time: {result['inference_time_ms']:.1f}ms")
                    print(f"ðŸ”‹ Energy Consumed: {result['energy_consumed_wh']:.4f}Wh")
                    print(f"ðŸŽ¯ Confidence: {result['confidence_score']:.2f}")
                    print(f"ðŸ”„ Fallback Used: {result['fallback_used']}")
                    print(f"ðŸ“Š Total Duration: {duration:.2f}s")
                    print(f"ðŸ’¬ Response: {result['response'][:100]}...")
                    
                else:
                    print(f"âŒ Request failed: {response.status_code}")
                    print(f"Error: {response.text}")
                    
            except Exception as e:
                print(f"âŒ Test failed: {e}")
        
        # Get performance stats
        print(f"\nðŸ“ˆ Performance Statistics")
        print("=" * 30)
        
        try:
            response = await client.get(f"{base_url}/stats")
            if response.status_code == 200:
                stats = response.json()
                print(f"ðŸ“Š Total Inferences: {stats.get('total_inferences', 0)}")
                print(f"âœ… Success Rate: {stats.get('success_rate', 0):.2%}")
                print(f"ðŸ”„ Fallback Rate: {stats.get('fallback_rate', 0):.2%}")
                print(f"âš¡ Avg Inference Time: {stats.get('average_inference_time_ms', 0):.1f}ms")
                print(f"ðŸ”‹ Energy Efficiency vs Transformer: {stats.get('energy_efficiency_vs_transformer', 'N/A')}")
        except Exception as e:
            print(f"âŒ Stats failed: {e}")

if __name__ == "__main__":
    asyncio.run(test_phoenix_router())
EOF

chmod +x test_phoenix_router.py

echo -e "${GREEN}âœ… Script de test creado${NC}"

# Crear docker-compose para monitorizaciÃ³n
echo -e "${BLUE}ðŸ“Š Creando configuraciÃ³n de monitorizaciÃ³n...${NC}"

cat > docker-compose.monitoring.yml << 'EOF'
version: '3.8'

services:
  prometheus:
    image: prom/prometheus:latest
    container_name: phoenix-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
    networks:
      - phoenix-monitoring

  grafana:
    image: grafana/grafana:latest
    container_name: phoenix-grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=phoenix123
    volumes:
      - grafana-storage:/var/lib/grafana
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./grafana/datasources:/etc/grafana/provisioning/datasources
    networks:
      - phoenix-monitoring

volumes:
  grafana-storage:

networks:
  phoenix-monitoring:
    driver: bridge
EOF

# Crear configuraciÃ³n de Prometheus
mkdir -p monitoring
cat > monitoring/prometheus.yml << 'EOF'
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'phoenix-router'
    static_configs:
      - targets: ['host.docker.internal:8000']
    metrics_path: '/metrics'
    scrape_interval: 10s
EOF

echo -e "${GREEN}âœ… ConfiguraciÃ³n de monitorizaciÃ³n creada${NC}"

# Instrucciones finales
echo -e "${GREEN}"
echo "ðŸŽ‰ Setup completado!"
echo "==================="
echo -e "${NC}"
echo "ðŸ“‹ PrÃ³ximos pasos:"
echo ""
echo "1. ðŸš€ Iniciar el router:"
echo "   python src/phoenix_system_review/mamba_integration/phoenix_model_router.py"
echo ""
echo "2. ðŸ§ª Ejecutar tests:"
echo "   python test_phoenix_router.py"
echo ""
echo "3. ðŸ“Š Iniciar monitorizaciÃ³n (opcional):"
echo "   docker-compose -f docker-compose.monitoring.yml up -d"
echo "   Grafana: http://localhost:3000 (admin/phoenix123)"
echo "   Prometheus: http://localhost:9090"
echo ""
echo "4. ðŸ” Test manual:"
echo "   curl -X POST http://localhost:8000/phoenixquery \\"
echo "        -H 'Content-Type: application/json' \\"
echo "        -d '{\"task\": \"Explica la eficiencia de Mamba\"}'"
echo ""
echo -e "${BLUE}ðŸ“š DocumentaciÃ³n:${NC}"
echo "   - Health Check: http://localhost:8000/health"
echo "   - Stats: http://localhost:8000/stats"
echo "   - Models: http://localhost:8000/models"
echo "   - API Docs: http://localhost:8000/docs"
echo ""
echo -e "${GREEN}âœ¨ Phoenix DemiGod estÃ¡ listo para procesamiento 100% local!${NC}"