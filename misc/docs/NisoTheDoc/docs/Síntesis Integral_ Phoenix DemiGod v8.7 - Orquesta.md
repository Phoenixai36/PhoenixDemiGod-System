<img src="https://r2cdn.perplexity.ai/pplx-full-logo-primary-dark%402x.png" class="logo" width="120"/>

# SÃ­ntesis Integral: Phoenix DemiGod v8.7 - Orquestador Roo Code + Flujo DevOps

## Prompt Maestro Unificado para Roo Code Orquestador

### Identidad y FunciÃ³n Central

```markdown
# ROO CODE ORQUESTADOR - PHOENIX DEMIGOD v8.7

Eres el orquestador principal de Phoenix DemiGod v8.7, un sistema de IA local avanzado con capacidades de reasoning, automatizaciÃ³n y edge computing. Tu funciÃ³n es coordinar, optimizar y ejecutar tareas complejas utilizando todos los recursos disponibles del stack, integrÃ¡ndote perfectamente con el entorno DevOps basado en VS Code.

## CONTEXTO DEL SISTEMA

### Stack TecnolÃ³gico Disponible:
- **Windmill**: AutomatizaciÃ³n y workflows (puerto 8001)
- **Ollama**: Modelos IA locales (puerto 11434)
- **Hugging Face**: Modelos avanzados en /workspace/hf-data
- **Podman**: OrquestaciÃ³n de contenedores
- **VS Code**: Entorno de desarrollo integrado y centro de comando
- **Persistencia**: D:\BooPhoenix\ (todos los volÃºmenes)
- **Git**: Control de versiones integrado

### Modelos IA Disponibles:

**Ollama:**
- llama3:8b - Razonamiento general y multiidioma
- mistral:7b - Tareas rÃ¡pidas y eficientes  
- mixtral:8x7b - Tareas complejas MoE
- deepseek-coder-v2 - GeneraciÃ³n de cÃ³digo
- qwen2.5-coder:7b - CÃ³digo y reasoning tÃ©cnico
- gemma:7b - Eficiencia y reasoning
- phi3:14b - Creatividad y multimodalidad
- falcon:7b - SSM/Mamba eficiente

**Hugging Face:**
- Zyphra/Zamba2-7B-Instruct - Reasoning avanzado SSM-Mamba
- Zyphra/BlackMamba-2.8B - SSM+MoE ultra eficiente
- Zyphra/ZR1-1.5B - Reasoning matemÃ¡tico y cÃ³digo
- Zyphra/Zonos-v0.1-hybrid - TTS multilingÃ¼e
- NousResearch/Nous-Hermes-2-Mixtral-8x7B-SFT - Chat avanzado
- Phind/Phind-CodeLlama-34B-v2 - CÃ³digo especializado
```


## IntegraciÃ³n DevOps con VS Code

### Estructura de Workspace Optimizada

```
D:\BooPhoenix\
â”‚
â”œâ”€â”€ windmill-data/          # Datos de Windmill
â”œâ”€â”€ windmill-db/            # Base de datos PostgreSQL
â”œâ”€â”€ windmill-backup/        # Backups automatizados
â”œâ”€â”€ ollama-data/            # Modelos Ollama
â”œâ”€â”€ hf-data/               # Modelos Hugging Face
â”œâ”€â”€ scripts/               # Scripts de automatizaciÃ³n
â”‚   â”œâ”€â”€ start-stack.ps1
â”‚   â”œâ”€â”€ download-hf-models.sh
â”‚   â”œâ”€â”€ backup-system.py
â”‚   â””â”€â”€ benchmark-models.py
â”œâ”€â”€ workflows/             # Scripts Windmill y Python
â”‚   â”œâ”€â”€ roo-orchestrator.py
â”‚   â”œâ”€â”€ test-ollama-integration.py
â”‚   â””â”€â”€ multi-model-consensus.py
â”œâ”€â”€ docs/                  # DocumentaciÃ³n
â”œâ”€â”€ .env                   # Variables de entorno
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```


## Capacidades Integradas del Orquestador

### 1. SelecciÃ³n Inteligente de Modelos con DevOps

**AnÃ¡lisis Automatizado:**

- EvalÃºa complejidad computacional desde VS Code
- Selecciona modelo Ã³ptimo basado en recursos disponibles
- Implementa validaciÃ³n cruzada con mÃºltiples modelos
- Registra decisiones en logs de Windmill

**ImplementaciÃ³n en VS Code:**

```python
# workflows/model-selector.py
import requests
import json
from typing import Dict, List

class ModelOrchestrator:
    def __init__(self):
        self.ollama_url = "http://localhost:11434/api/generate"
        self.models = {
            "reasoning": ["zamba2-7b-instruct", "llama3:8b"],
            "coding": ["deepseek-coder-v2", "qwen2.5-coder:7b"],
            "fast": ["mistral:7b", "gemma:7b"],
            "complex": ["mixtral:8x7b", "nous-hermes-2-mixtral"]
        }
    
    def select_optimal_model(self, task_type: str, complexity: str):
        """Selecciona el modelo Ã³ptimo basado en tipo y complejidad"""
        if task_type == "reasoning" and complexity == "high":
            return self.models["reasoning"][0]  # Zamba2-7B
        elif task_type == "coding":
            return self.models["coding"][0]     # DeepSeek-Coder
        else:
            return self.models["fast"][0]       # Mistral-7B
```


### 2. OrquestaciÃ³n de Workflows DevOps

**GestiÃ³n de Contenedores desde VS Code:**

```powershell
# scripts/start-stack.ps1
Write-Host "ðŸš€ Iniciando Phoenix DemiGod v8.7..."
podman start windmill-db
podman start windmill  
podman start ollama
Write-Host "âœ… Stack activo. Acceso: Windmill (8001), Ollama (11434)"
```

**MonitorizaciÃ³n Integrada:**

```python
# workflows/system-monitor.py
import subprocess
import json

def check_system_health():
    """Verifica estado de contenedores y recursos"""
    containers = subprocess.run(
        ["podman", "ps", "--format", "json"], 
        capture_output=True, text=True
    )
    
    stats = subprocess.run(
        ["podman", "stats", "--no-stream", "--format", "json"],
        capture_output=True, text=True
    )
    
    return {
        "containers": json.loads(containers.stdout),
        "resources": json.loads(stats.stdout),
        "timestamp": datetime.now().isoformat()
    }
```


### 3. Reasoning Avanzado con ValidaciÃ³n DevOps

**Protocolos de Consenso Multi-Modelo:**

```python
# workflows/multi-model-consensus.py
def multi_model_reasoning(prompt: str, models: List[str], strategy: str = "consensus"):
    """
    Implementa reasoning con mÃºltiples modelos y validaciÃ³n cruzada
    """
    results = {}
    
    for model in models:
        try:
            response = query_ollama_model(model, prompt)
            results[model] = {
                "response": response.get("response", ""),
                "eval_duration": response.get("eval_duration", 0),
                "load_duration": response.get("load_duration", 0)
            }
        except Exception as e:
            results[model] = {"error": str(e)}
    
    if strategy == "consensus":
        return analyze_consensus(results)
    elif strategy == "performance":
        return select_fastest_accurate(results)
    else:
        return results
```


## Variables de Entorno Unificadas

```python
# .env - ConfiguraciÃ³n centralizada
OLLAMA_API_URL=http://localhost:11434/api/generate
HF_MODELS_PATH=/workspace/hf-data
WINDMILL_BASE_URL=http://localhost:8001
SYSTEM_DATA_PATH=D:/BooPhoenix/
PODMAN_MACHINE=defaultizzy-root

# ConfiguraciÃ³n de modelos por categorÃ­a
REASONING_MODELS=["zamba2-7b-instruct", "llama3:8b"]
CODING_MODELS=["deepseek-coder-v2", "qwen2.5-coder:7b"]
FAST_MODELS=["mistral:7b", "gemma:7b"]
COMPLEX_MODELS=["mixtral:8x7b", "nous-hermes-2-mixtral"]
```


## Protocolos de OperaciÃ³n Integrados

### Flujo de Trabajo Completo en VS Code

**1. ConfiguraciÃ³n del Workspace:**

- Abrir `D:\BooPhoenix` en VS Code
- Instalar extensiones: Python, Docker, GitLens, DotENV
- Configurar terminal integrada para PowerShell

**2. GestiÃ³n de Servicios:**

```powershell
# Verificar estado
podman ps -a

# Ejecutar stack completo
.\scripts\start-stack.ps1

# Monitorizar recursos
podman stats
```

**3. Desarrollo y Testing:**

```python
# workflows/test-integration.py
def test_roo_orchestrator():
    """Prueba completa del orquestador"""
    tests = [
        ("reasoning", "Explica la teorÃ­a de la relatividad"),
        ("coding", "Crea una funciÃ³n para ordenar una lista"),
        ("fast", "Â¿CuÃ¡l es la capital de Francia?")
    ]
    
    for task_type, prompt in tests:
        model = select_optimal_model(task_type, "medium")
        result = execute_task(model, prompt)
        validate_response(result)
        log_performance(task_type, model, result)
```

**4. Control de Versiones:**

```bash
# Workflow Git integrado
git checkout -b feature/enhanced-reasoning
git add workflows/
git commit -m "feat: add multi-model consensus reasoning"
git push origin feature/enhanced-reasoning
```

**5. MonitorizaciÃ³n en Tiempo Real:**

```powershell
# Logs en vivo
podman logs -f windmill
podman logs -f ollama

# MÃ©tricas de rendimiento
podman stats --format "table {{.Container}}\t{{.CPUPerc}}\t{{.MemUsage}}"
```


## Directrices de Seguridad y Rendimiento

### Seguridad DevOps

- **ValidaciÃ³n de entrada:** Sanitizar prompts antes de enviar a modelos
- **GestiÃ³n de secretos:** Variables sensibles en `.env` (nunca en Git)
- **Backups automÃ¡ticos:** Scripts de backup programados en Windmill
- **MonitorizaciÃ³n de recursos:** Alertas automÃ¡ticas por sobrecarga


### OptimizaciÃ³n de Rendimiento

- **CachÃ© inteligente:** Respuestas frecuentes en Redis/memoria
- **Balanceador de carga:** DistribuciÃ³n automÃ¡tica entre modelos
- **MÃ©tricas en tiempo real:** Dashboard en Windmill para KPIs
- **Escalado dinÃ¡mico:** Ajuste automÃ¡tico de recursos segÃºn demanda


## Formato de Respuesta Estandarizado

Para cada tarea ejecutada por Roo Code:

```json
{
  "analysis": "EvaluaciÃ³n de la tarea y estrategia seleccionada",
  "selected_models": {
    "primary": "modelo_principal",
    "secondary": "modelo_validacion",
    "justification": "razÃ³n_de_selecciÃ³n"
  },
  "execution": {
    "steps": ["paso1", "paso2", "paso3"],
    "commands": ["comando1", "comando2"],
    "duration": "tiempo_total"
  },
  "validation": {
    "accuracy": "precisiÃ³n_respuesta",
    "performance": "mÃ©tricas_rendimiento",
    "consensus": "nivel_consenso_multi_modelo"
  },
  "logs": {
    "timestamp": "iso_timestamp",
    "container_status": "estado_contenedores",
    "resource_usage": "uso_recursos",
    "errors": "errores_encontrados"
  }
}
```


## Script de InicializaciÃ³n Completo

```python
# workflows/initialize-phoenix-demigod.py
def initialize_phoenix_demigod():
    """
    InicializaciÃ³n completa del sistema Phoenix DemiGod v8.7
    """
    print("ðŸ”¥ Inicializando Phoenix DemiGod v8.7...")
    
    # 1. Verificar contenedores
    container_status = check_container_status()
    
    # 2. Validar modelos disponibles
    ollama_models = check_ollama_models()
    hf_models = check_hf_models()
    
    # 3. Configurar variables de entorno
    load_environment_variables()
    
    # 4. Inicializar orquestador Roo Code
    roo_status = initialize_roo_orchestrator()
    
    # 5. Ejecutar pruebas de conectividad
    connectivity_tests = run_connectivity_tests()
    
    return {
        "status": "ready",
        "version": "8.7.2",
        "components": {
            "containers": container_status,
            "ollama_models": ollama_models,
            "hf_models": hf_models,
            "roo_orchestrator": roo_status,
            "connectivity": connectivity_tests
        },
        "timestamp": datetime.now().isoformat()
    }
```


## Resumen Ejecutivo

Esta sÃ­ntesis integra el **Prompt Maestro para Roo Code Orquestador** con el **Flujo DevOps de 7 pasos en VS Code**, creando un sistema unificado donde:

- **Roo Code** actÃºa como cerebro central de Phoenix DemiGod v8.7
- **VS Code** sirve como centro de comando y desarrollo
- **Los workflows DevOps** garantizan calidad, trazabilidad y escalabilidad
- **La orquestaciÃ³n multi-modelo** maximiza rendimiento y precisiÃ³n
- **La automatizaciÃ³n inteligente** reduce complejidad operacional

El resultado es un entorno profesional de IA local que combina potencia tÃ©cnica, facilidad de uso y robustez operacional, preparado para cualquier reto de reasoning, automatizaciÃ³n o desarrollo en el ecosistema Phoenix DemiGod.

